# -*- coding: utf-8 -*-
"""Copy of pcos1a.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1o3kLoj3KRDJslJDXTLXRTz62VvmPj36P
"""

from google.colab import drive
drive.mount('/content/drive')

import keras
import numpy as np
from keras import models
from keras import layers
from keras import optimizers
import matplotlib.pyplot as plt
from keras.optimizers import SGD, Adam
from keras.models import Model
from keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten, SeparableConv2D,AveragePooling2D,GlobalAveragePooling2D,GlobalMaxPooling2D
import os,cv2
from sklearn.model_selection import train_test_split

import os
import pandas as pd
import shutil

image_folder="/content/drive/MyDrive/PCOS-Hack/PCOSGen-train/PCOSGen-train/images"
excel_file="/content/drive/MyDrive/PCOS-Hack/PCOSGen-train/PCOSGen-train/class_label.xlsx"
df=pd.read_excel(excel_file)
for index, row in df.iterrows():
    image_filename=row['imagePath']
    class_description = str(row['Healthy'])

    src_path = os.path.join(image_folder, image_filename)
    dst_folder = os.path.join("/content/drive/MyDrive/PCOS-Hack/Dest_folder", class_description)
    if os.path.exists(src_path):
        # Create the destination folder if it doesn't exist
        os.makedirs(dst_folder, exist_ok=True)

        # Move the image to the destination folder
        shutil.move(src_path, os.path.join(dst_folder, image_filename))
        print(f"Moved {image_filename} to {dst_folder}")
    else:
        print(f"File {image_filename} not found in {src_path}")

print("Separation complete.")

"""AUGMENTING DATA"""

from PIL import Image
import os
import imgaug.augmenters as iaa

def check_image_validity(image_path):
    try:
        img = Image.open(image_path)
        img.load()  # Attempt to load the image data
        # print(f"Image '{os.path.basename(image_path)}' is valid and can be opened.")
        return True
    except Exception as e:
        # print(f"Error opening image '{os.path.basename(image_path)}': {e}")
        return False

import matplotlib.pyplot as plt
from scipy import ndimage
import cv2


input_folder = '/content/drive/MyDrive/PCOS-Hack/Dest_folder/1/'
output_folder = '/content/drive/MyDrive/PCOS-Hack/Dest_folder/1_augmented/'

for img in os.listdir(input_folder):
    i = 0
    input_img = cv2.imread(os.path.join(input_folder, img))
    # input_img = cv2.resize(input_img, (64, 64))
    input_img = input_img / 255.0  # Scale pixel values between 0 and 1

    output_filename = str(i)+'_'+img
    output_path = os.path.join(output_folder, output_filename)
    cv2.imwrite(output_path,input_img*255)
    i = i+1

    rotated = ndimage.rotate(input_img, 15)
    # rotated = cv2.resize(rotated, (64, 64))
    output_filename = str(i)+'_'+img
    output_path = os.path.join(output_folder, output_filename)
    cv2.imwrite(output_path,rotated*255)
    i = i+1

    flipped = cv2.flip(rotated, 1)
    output_filename = str(i)+'_'+img
    output_path = os.path.join(output_folder, output_filename)
    cv2.imwrite(output_path,flipped*255)
    i = i+1
    # plt.imshow(rotated)
    # plt.show()

img_data_list = []
labels = []

data_path = '/content/drive/MyDrive/PCOS-Hack/Dest_folder/0'
for dataset in os.listdir(data_path):
    # img_list=os.listdir(data_path+'/'+ dataset)
    # print ('Loaded the images of dataset-'+'{}\n'.format(dataset))
    # i = 0
    # for img in img_list:
      # if i<30:
    input_img=cv2.imread(data_path + '/'+ dataset)
    input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2RGB)
    labels.append('0')
    # print(input_img.shape)
    input_img_resize=cv2.resize(input_img,(224,224))
    input_img_resize=cv2.normalize(input_img_resize,None,0,255,cv2.NORM_MINMAX)
    img_data_list.append(input_img_resize)
    # i=i+1

data_path = '/content/drive/MyDrive/PCOS-Hack/Dest_folder/1_augmented'
for dataset in os.listdir(data_path):
    # img_list=os.listdir(data_path+'/'+ dataset)
    # print ('Loaded the images of dataset-'+'{}\n'.format(dataset))
    # i = 0
    # for img in img_list:
      # if i<30:
    input_img=cv2.imread(data_path + '/'+ dataset)
    input_img=cv2.cvtColor(input_img, cv2.COLOR_BGR2RGB)
    labels.append('1')
    # print(input_img.shape)
    input_img_resize=cv2.resize(input_img,(224,224))
    input_img_resize=cv2.normalize(input_img_resize,None,0,255,cv2.NORM_MINMAX)
    img_data_list.append(input_img_resize)
    # i=i+1

# labels = np.array(labels)
img_data = np.array(img_data_list)
print(img_data.shape)

from keras.utils import to_categorical
num_classes = 2
label = to_categorical(labels, num_classes)

label

x_train, x_val, y_train, y_val = train_test_split(img_data, label, test_size=0.2)

# Print the train set
print('Train Set')
print(x_train.shape)
print(y_train.shape)

# Print the validation set
print('Validation Set')
print(x_val.shape)
print(y_val.shape)

plt.figure(figsize=(8, 8))
for i in range(1, 2):
  plt.subplot(4, 4, i)
  img= x_val[i]
  plt.imshow(img)
plt.show()

from keras.layers import GlobalAveragePooling2D, GlobalMaxPooling2D, Reshape, Dense, Multiply, Permute, Concatenate, Conv2D, Add, Activation, Lambda
from keras import backend as K
from keras.activations import sigmoid
from keras.layers import Flatten, Dense, Input, Conv2D, MaxPooling2D, Dropout, Add, BatchNormalization, Conv1D
import tensorflow as tf
from keras.models import Model
from keras.layers import Layer, Conv2D, Multiply, Add

from keras.layers import Layer, Conv2D, Multiply, Add, Activation
import tensorflow as tf

class ECA(Layer):
    def __init__(self, gamma=2, **kwargs):
        super(ECA, self).__init__(**kwargs)
        self.gamma = gamma

    def build(self, input_shape):
        channels = input_shape[-1]
        self.conv = Conv2D(filters=1, kernel_size=1, kernel_initializer='he_normal', activation='sigmoid')
        self.gamma = self.add_weight("gamma", (1, 1, channels), initializer="ones", trainable=True)

    def call(self, inputs):
        weights = self.conv(inputs)
        weighted_inputs = Multiply()([inputs, weights])
        scaled_inputs = Multiply()([inputs, self.gamma])
        output = Add()([weighted_inputs, scaled_inputs])
        return output

def eca_block(input_tensor):
    eca_feature = ECA()(input_tensor)
    return eca_feature



# class ECA(Layer):
    # def __init__(self, **kwargs):
        # super(ECA, self).__init__(**kwargs)

    # def build(self, input_shape):
        # channels = input_shape[-1]
        # self.conv = Conv2D(filters=1, kernel_size=1, kernel_initializer='he_normal', activation='sigmoid')
        # self.gamma = self.add_weight("gamma", (channels,), initializer="ones", trainable=True)

    # def call(self, inputs):
        # weights = self.conv(inputs)
        # inputs_shape = inputs.get_shape()
        # weights = Multiply()([inputs, weights])
        # output = Add()([inputs, Multiply()([inputs, self.gamma, weights])])
        # return output

# def eca_block(eca_feature):
    # eca_feature = ECA()(eca_feature)
    # return eca_feature

def channel_attention(input_feature, ratio=8):
    H, W, C = map(int, input_feature.get_shape()[1:])
    channel = C

    shared_layer_one = Dense(channel//ratio,
                             activation='relu',
                             kernel_initializer='he_normal',
                             use_bias=True,
                             bias_initializer='zeros')
    shared_layer_two = Dense(channel,
                             kernel_initializer='he_normal',
                             use_bias=True,
                             bias_initializer='zeros')

    avg_pool = GlobalAveragePooling2D()(input_feature)
    avg_pool = Reshape((1,1,channel))(avg_pool)
    avg_pool = shared_layer_one(avg_pool)
    avg_pool = shared_layer_two(avg_pool)

    max_pool = GlobalMaxPooling2D()(input_feature)
    max_pool = Reshape((1,1,channel))(max_pool)
    max_pool = shared_layer_one(max_pool)
    max_pool = shared_layer_two(max_pool)

    eca_feature = Add()([avg_pool,max_pool])
    eca_feature = Activation('sigmoid')(eca_feature)

    if K.image_data_format() == "channels_first":
        eca_feature = Permute((3, 1, 2))(eca_feature)

    return Multiply()([input_feature, eca_feature])

def spatial_attention(input_feature):
    kernel_size = 7
    H, W, C = map(int, input_feature.get_shape()[1:])
    if K.image_data_format() == "channels_first":
        channel = C
        eca_feature = Permute((2,3,1))(input_feature)
    else:
        channel = C
        eca_feature = input_feature

    avg_pool = Lambda(lambda x: K.mean(x, axis=3, keepdims=True))(eca_feature)
    max_pool = Lambda(lambda x: K.max(x, axis=3, keepdims=True))(eca_feature)
    concat = Concatenate(axis=3)([avg_pool, max_pool])

    eca_feature = Conv2D(filters = 1,
                    kernel_size=kernel_size,
                    strides=1,
                    padding='same',
                    activation='sigmoid',
                    kernel_initializer='he_normal',
                    use_bias=False)(concat)

    if K.image_data_format() == "channels_first":
        eca_feature = Permute((3, 1, 2))(eca_feature)

    return Multiply()([input_feature, eca_feature])

from keras.layers import Add, Concatenate, Dense, Conv2D, GlobalMaxPooling2D, MaxPooling2D, Input, Flatten
from keras.models import Model

input_layer = Input(shape=(224, 224, 3))

# First block
x = Conv2D(32, (3,3), activation='relu')(input_layer)
x1 = Conv2D(32, (3,3), padding='same', activation='relu')(x)
x2 = Conv2D(32, (3,3), padding='same', activation='relu')(x)
a1 = Add()([x1, x2])
att1 = eca_block(a1)
g1 = GlobalMaxPooling2D()(att1)

m1 = MaxPooling2D(pool_size=2, strides=2)(a1)

# Second block
x = Conv2D(32, (3,3), activation='relu')(m1)  # Use the same number of filters as in the first block
x1 = Conv2D(32, (3,3), padding='same', activation='relu')(x)
x2 = Conv2D(32, (3,3), padding='same', activation='relu')(x)
a2 = Add()([x1, x2])
att2 = eca_block(a2)
g2 = GlobalMaxPooling2D()(att2)

m2 = MaxPooling2D(pool_size=2, strides=2)(a2)

# Third block
x = Conv2D(32, (3,3), activation='relu')(input_layer)  # Use the same number of filters as in the first block
x1 = Conv2D(32, (3,3), padding='same', activation='relu')(x)
x2 = Conv2D(32, (3,3), padding='same', activation='relu')(x)
a3 = Add()([x1, x2])
att3 = eca_block(a3)
g3 = GlobalMaxPooling2D()(att3)

# Flatten the outputs
flatten1 = Flatten()(g1)
flatten2 = Flatten()(g2)
flatten3 = Flatten()(g3)

# Concatenate the flattened outputs
concatenated = Concatenate()([flatten1, flatten2, flatten3])

# Dense layers for classification
dense1 = Dense(512, activation='relu')(concatenated)
dense2 = Dense(256, activation='relu')(dense1)
output = Dense(2, activation='softmax')(dense2)

model = Model(inputs=input_layer, outputs=output)
model.summary()

from keras.callbacks import EarlyStopping, ModelCheckpoint
early_stopping = EarlyStopping(
                              patience=30,
                              min_delta=0.001,
                              monitor="val_accuracy",
                              restore_best_weights=True
                              )
# Define the model checkpoint callback to save the best weights
checkpoint = ModelCheckpoint('/content/drive/MyDrive/PCOS-Hack/checkpoints'+'-{epoch:02d}.h5', monitor='val_accuracy', save_best_only=True)

from keras import optimizers as optim
from keras import backend as K
from keras import optimizers
from keras.optimizers import RMSprop

model.compile(loss='categorical_crossentropy',optimizer = RMSprop(learning_rate=0.001),metrics=['accuracy'])
# Train the model
history = model.fit(x_train, y_train, epochs=80, batch_size=16, validation_data=(x_val, y_val),callbacks=[early_stopping, checkpoint], verbose=1)

model.save(my_model)

